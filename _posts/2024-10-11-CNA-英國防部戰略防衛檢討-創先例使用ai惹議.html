---
layout: post
title: 英國防部戰略防衛檢討  創先例使用AI惹議
date: 2024-10-11 01:34:03.000000000 +08:00
link: https://www.cna.com.tw/news/aopl/202410100321.aspx
categories: cna
---

<div></div><div><p>（中央社記者陳韻聿倫敦10日專電）英國政府7月中旬啟動「戰略防衛檢討」（SDR），目前已進入公共意見彙整階段，卻因為是英國中央政府機關首次在這類大型政策工程使用人工智慧（AI）分析工具，而引發討論。</p><p>SDR的目標為以專業獨立的精神，全盤檢視英國面臨的安全防衛威脅及應對相關威脅的能力，以利後續政策規劃和執行。根據國防部之前發布的時程，軍方、產業、智庫等各界意見應於10月進入分析彙整階段。</p><p>政治新聞網站Politico報導，相關分析彙整將使用AI工具，這是英國中央政府部會首次在重大政策檢討運用AI，可視為政府推動公務體系「科技化」的一環。</p><p>英國國防部已證實，將運用客製化AI分析彙整各界就SDR所涵蓋議題分別提出的意見。</p><p>根據報導，相關AI模型由美國科技公司帕蘭泰爾（Palantir）打造。帕蘭泰爾是在今年夏天贏得合約。</p><p>不過，英國安全防衛產業界及學界部分人士對借助AI完成SDR有疑慮。一名防衛事務專家指出，相關工具恐成為「特洛伊木馬」，讓惡意行為者有機可乘、駭入英國政府系統。另一名專家則說，像SDR這麼重大的政策檢討不適合拿來實驗AI。</p><p>帕蘭泰爾打造的AI工具將透過檢索關鍵詞、題目等，分析彙整國防部收到的數以千計SDR相關意見，並擬具概要，供官員參考。</p><p>牛津大學教授、防衛科技倫理專家泰德歐（Mariarosaria Taddeo）同時是國防部數個委員會的獨立顧問。她指出，以AI輔助決策，這本身不是問題，令人有疑問的是AI是否僅扮演輔助角色、使用者是否能以批判眼光檢視AI。</p><p>此外，AI工具如何被設計、有什麼樣的人涉入，以及已執行什麼樣的測試以避免、排除AI內建偏見，也值得思考。</p><p>泰德歐另提醒資安風險。她指出，AI其實很脆弱，即便僅供內部使用，也可能遭遇攻擊。</p><p>關於AI內建「偏見」，一名防衛產業界人士透露，部分企業試圖「耍弄」系統，透過重複特定字詞提升己方意見通過篩選的機率。</p><p>業界人士指出，分析彙整資料時，真人參與不足恐導致重要資訊遭遺漏，而另一些資訊則被不公平、不合理地放大。</p><p>不過，政府官員強調，AI產出的資訊將持續被真人檢視。英國國防部一名發言人表示，國防部一向對自身在國防領域廣泛運用AI科技的野心保持透明態度，SDR團隊正運用AI分析檢視各界就SDR提出的大量資料與意見。</p><p>這名發言人提到，SDR的徵詢對象廣泛，涵蓋現役與退役軍人、各黨籍國會議員、產業界、學界、大眾。</p><p>至於SDR何時完成，3名知情人士告訴Politico，SDR預計明年3月或更早之前發布，官方的政策回應則預計在明年夏天前提出。（編輯：唐佩君）1131010</p>
